import osimport djangofrom django.utils.text import slugifyfrom scraper.celery_config import appfrom stores.KTC.ktc_info import KTC_ARTICLESfrom stores.KTC.ktc_model import KtcStorefrom stores.KTC.locators import KtcLocatorfrom utillities import custom_article_extractorfrom django.utils.timezone import nowfrom django.db import transactionfrom celery import shared_taskimport loggingos.environ.setdefault("DJANGO_SETTINGS_MODULE", "scraper.settings")django.setup()from checker.models import ScrapedData, Partner, ScrapedItem@app.task(name='stores.KTC.tasks.start_ktc_wacom')def start_ktc_wacom():    ktc = KtcStore(url=KtcLocator.WACOM_PAGE_URL)    ktc.load_items(container_locator=KtcLocator.CATALOG_GOODS, item_locator=KtcLocator.ITEM_LOOP)    items = ktc.generate_info_with_articles(        title_locator=KtcLocator.ITEM_TITLE,        price_locator=KtcLocator.ITEM_PRICE,        status_locator=KtcLocator.ITEM_STATUS,        article_extractor=lambda name: custom_article_extractor(name, KTC_ARTICLES))    return items# Налаштування логуванняlogger = logging.getLogger(__name__)@shared_task(name='stores.KTC.tasks.start_ktc_xp_pen')def start_ktc_xp_pen():    ktc = KtcStore(url=KtcLocator.XP_PEN_PAGE_URL)    ktc.load_items(container_locator=KtcLocator.CATALOG_GOODS, item_locator=KtcLocator.ITEM_LOOP)    items = ktc.generate_info_with_articles(        title_locator=KtcLocator.ITEM_TITLE,        price_locator=KtcLocator.ITEM_PRICE,        status_locator=KtcLocator.ITEM_STATUS,        article_extractor=lambda name: custom_article_extractor(name, KTC_ARTICLES)    )    save_parsed_data(partner_name="KTC", items=items)    return items@app.task()def save_parsed_data(partner_name: str, items: list):    try:        partner, created = Partner.objects.get_or_create(name=partner_name)        with transaction.atomic():            scraped_data = ScrapedData.objects.create(partner=partner)            # Список для масового створення товарів            items_to_create = []            for item in items:                # Перевіряємо, чи є товар з таким артикулом                existing_item = ScrapedItem.objects.filter(article=item.get('article')).first()                if existing_item:                    # Якщо товар вже існує, додаємо його до ScrapedData                    scraped_data.items.add(existing_item)                else:                    # Створюємо новий товар                    new_item = ScrapedItem(                        name=item.get('name'),                        price=item.get('price'),                        article=item.get('article'),                        status=item.get('status')                    )                    items_to_create.append(new_item)            # Масове створення нових товарів            if items_to_create:                ScrapedItem.objects.bulk_create(items_to_create, ignore_conflicts=True)            # Додаємо нові товари до ScrapedData            new_items = ScrapedItem.objects.filter(article__in=[item.article for item in items_to_create])            scraped_data.items.add(*new_items)            # Оновлюємо час останнього оновлення            scraped_data.last_update = now()            scraped_data.save()            # Логування            logger.info(f"Парсинг для партнера {partner_name} завершено. Збережено {len(items)} товарів.")    except Exception as e:        # Логування помилки        logger.error(f"Помилка при збереженні даних парсингу для партнера {partner_name}: {str(e)}")    return items